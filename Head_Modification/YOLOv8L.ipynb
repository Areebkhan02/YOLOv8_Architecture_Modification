{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/areebadnan/Areeb_code/work/Atheritia/Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia\n",
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_Python_Environments/yolo_env1/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/nn/tasks.py:785: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.model.0.conv.weight', 'model.model.0.bn.weight', 'model.model.0.bn.bias', 'model.model.0.bn.running_mean', 'model.model.0.bn.running_var', 'model.model.0.bn.num_batches_tracked', 'model.model.1.conv.weight', 'model.model.1.bn.weight', 'model.model.1.bn.bias', 'model.model.1.bn.running_mean', 'model.model.1.bn.running_var', 'model.model.1.bn.num_batches_tracked', 'model.model.2.cv1.conv.weight', 'model.model.2.cv1.bn.weight', 'model.model.2.cv1.bn.bias', 'model.model.2.cv1.bn.running_mean', 'model.model.2.cv1.bn.running_var', 'model.model.2.cv1.bn.num_batches_tracked', 'model.model.2.cv2.conv.weight', 'model.model.2.cv2.bn.weight', 'model.model.2.cv2.bn.bias', 'model.model.2.cv2.bn.running_mean', 'model.model.2.cv2.bn.running_var', 'model.model.2.cv2.bn.num_batches_tracked', 'model.model.2.m.0.cv1.conv.weight', 'model.model.2.m.0.cv1.bn.weight', 'model.model.2.m.0.cv1.bn.bias', 'model.model.2.m.0.cv1.bn.running_mean', 'model.model.2.m.0.cv1.bn.running_var', 'model.model.2.m.0.cv1.bn.num_batches_tracked', 'model.model.2.m.0.cv2.conv.weight', 'model.model.2.m.0.cv2.bn.weight', 'model.model.2.m.0.cv2.bn.bias', 'model.model.2.m.0.cv2.bn.running_mean', 'model.model.2.m.0.cv2.bn.running_var', 'model.model.2.m.0.cv2.bn.num_batches_tracked', 'model.model.2.m.1.cv1.conv.weight', 'model.model.2.m.1.cv1.bn.weight', 'model.model.2.m.1.cv1.bn.bias', 'model.model.2.m.1.cv1.bn.running_mean', 'model.model.2.m.1.cv1.bn.running_var', 'model.model.2.m.1.cv1.bn.num_batches_tracked', 'model.model.2.m.1.cv2.conv.weight', 'model.model.2.m.1.cv2.bn.weight', 'model.model.2.m.1.cv2.bn.bias', 'model.model.2.m.1.cv2.bn.running_mean', 'model.model.2.m.1.cv2.bn.running_var', 'model.model.2.m.1.cv2.bn.num_batches_tracked', 'model.model.2.m.2.cv1.conv.weight', 'model.model.2.m.2.cv1.bn.weight', 'model.model.2.m.2.cv1.bn.bias', 'model.model.2.m.2.cv1.bn.running_mean', 'model.model.2.m.2.cv1.bn.running_var', 'model.model.2.m.2.cv1.bn.num_batches_tracked', 'model.model.2.m.2.cv2.conv.weight', 'model.model.2.m.2.cv2.bn.weight', 'model.model.2.m.2.cv2.bn.bias', 'model.model.2.m.2.cv2.bn.running_mean', 'model.model.2.m.2.cv2.bn.running_var', 'model.model.2.m.2.cv2.bn.num_batches_tracked', 'model.model.3.conv.weight', 'model.model.3.bn.weight', 'model.model.3.bn.bias', 'model.model.3.bn.running_mean', 'model.model.3.bn.running_var', 'model.model.3.bn.num_batches_tracked', 'model.model.4.cv1.conv.weight', 'model.model.4.cv1.bn.weight', 'model.model.4.cv1.bn.bias', 'model.model.4.cv1.bn.running_mean', 'model.model.4.cv1.bn.running_var', 'model.model.4.cv1.bn.num_batches_tracked', 'model.model.4.cv2.conv.weight', 'model.model.4.cv2.bn.weight', 'model.model.4.cv2.bn.bias', 'model.model.4.cv2.bn.running_mean', 'model.model.4.cv2.bn.running_var', 'model.model.4.cv2.bn.num_batches_tracked', 'model.model.4.m.0.cv1.conv.weight', 'model.model.4.m.0.cv1.bn.weight', 'model.model.4.m.0.cv1.bn.bias', 'model.model.4.m.0.cv1.bn.running_mean', 'model.model.4.m.0.cv1.bn.running_var', 'model.model.4.m.0.cv1.bn.num_batches_tracked', 'model.model.4.m.0.cv2.conv.weight', 'model.model.4.m.0.cv2.bn.weight', 'model.model.4.m.0.cv2.bn.bias', 'model.model.4.m.0.cv2.bn.running_mean', 'model.model.4.m.0.cv2.bn.running_var', 'model.model.4.m.0.cv2.bn.num_batches_tracked', 'model.model.4.m.1.cv1.conv.weight', 'model.model.4.m.1.cv1.bn.weight', 'model.model.4.m.1.cv1.bn.bias', 'model.model.4.m.1.cv1.bn.running_mean', 'model.model.4.m.1.cv1.bn.running_var', 'model.model.4.m.1.cv1.bn.num_batches_tracked', 'model.model.4.m.1.cv2.conv.weight', 'model.model.4.m.1.cv2.bn.weight', 'model.model.4.m.1.cv2.bn.bias', 'model.model.4.m.1.cv2.bn.running_mean', 'model.model.4.m.1.cv2.bn.running_var', 'model.model.4.m.1.cv2.bn.num_batches_tracked', 'model.model.4.m.2.cv1.conv.weight', 'model.model.4.m.2.cv1.bn.weight', 'model.model.4.m.2.cv1.bn.bias', 'model.model.4.m.2.cv1.bn.running_mean', 'model.model.4.m.2.cv1.bn.running_var', 'model.model.4.m.2.cv1.bn.num_batches_tracked', 'model.model.4.m.2.cv2.conv.weight', 'model.model.4.m.2.cv2.bn.weight', 'model.model.4.m.2.cv2.bn.bias', 'model.model.4.m.2.cv2.bn.running_mean', 'model.model.4.m.2.cv2.bn.running_var', 'model.model.4.m.2.cv2.bn.num_batches_tracked', 'model.model.4.m.3.cv1.conv.weight', 'model.model.4.m.3.cv1.bn.weight', 'model.model.4.m.3.cv1.bn.bias', 'model.model.4.m.3.cv1.bn.running_mean', 'model.model.4.m.3.cv1.bn.running_var', 'model.model.4.m.3.cv1.bn.num_batches_tracked', 'model.model.4.m.3.cv2.conv.weight', 'model.model.4.m.3.cv2.bn.weight', 'model.model.4.m.3.cv2.bn.bias', 'model.model.4.m.3.cv2.bn.running_mean', 'model.model.4.m.3.cv2.bn.running_var', 'model.model.4.m.3.cv2.bn.num_batches_tracked', 'model.model.4.m.4.cv1.conv.weight', 'model.model.4.m.4.cv1.bn.weight', 'model.model.4.m.4.cv1.bn.bias', 'model.model.4.m.4.cv1.bn.running_mean', 'model.model.4.m.4.cv1.bn.running_var', 'model.model.4.m.4.cv1.bn.num_batches_tracked', 'model.model.4.m.4.cv2.conv.weight', 'model.model.4.m.4.cv2.bn.weight', 'model.model.4.m.4.cv2.bn.bias', 'model.model.4.m.4.cv2.bn.running_mean', 'model.model.4.m.4.cv2.bn.running_var', 'model.model.4.m.4.cv2.bn.num_batches_tracked', 'model.model.4.m.5.cv1.conv.weight', 'model.model.4.m.5.cv1.bn.weight', 'model.model.4.m.5.cv1.bn.bias', 'model.model.4.m.5.cv1.bn.running_mean', 'model.model.4.m.5.cv1.bn.running_var', 'model.model.4.m.5.cv1.bn.num_batches_tracked', 'model.model.4.m.5.cv2.conv.weight', 'model.model.4.m.5.cv2.bn.weight', 'model.model.4.m.5.cv2.bn.bias', 'model.model.4.m.5.cv2.bn.running_mean', 'model.model.4.m.5.cv2.bn.running_var', 'model.model.4.m.5.cv2.bn.num_batches_tracked', 'model.model.5.conv.weight', 'model.model.5.bn.weight', 'model.model.5.bn.bias', 'model.model.5.bn.running_mean', 'model.model.5.bn.running_var', 'model.model.5.bn.num_batches_tracked', 'model.model.6.cv1.conv.weight', 'model.model.6.cv1.bn.weight', 'model.model.6.cv1.bn.bias', 'model.model.6.cv1.bn.running_mean', 'model.model.6.cv1.bn.running_var', 'model.model.6.cv1.bn.num_batches_tracked', 'model.model.6.cv2.conv.weight', 'model.model.6.cv2.bn.weight', 'model.model.6.cv2.bn.bias', 'model.model.6.cv2.bn.running_mean', 'model.model.6.cv2.bn.running_var', 'model.model.6.cv2.bn.num_batches_tracked', 'model.model.6.m.0.cv1.conv.weight', 'model.model.6.m.0.cv1.bn.weight', 'model.model.6.m.0.cv1.bn.bias', 'model.model.6.m.0.cv1.bn.running_mean', 'model.model.6.m.0.cv1.bn.running_var', 'model.model.6.m.0.cv1.bn.num_batches_tracked', 'model.model.6.m.0.cv2.conv.weight', 'model.model.6.m.0.cv2.bn.weight', 'model.model.6.m.0.cv2.bn.bias', 'model.model.6.m.0.cv2.bn.running_mean', 'model.model.6.m.0.cv2.bn.running_var', 'model.model.6.m.0.cv2.bn.num_batches_tracked', 'model.model.6.m.1.cv1.conv.weight', 'model.model.6.m.1.cv1.bn.weight', 'model.model.6.m.1.cv1.bn.bias', 'model.model.6.m.1.cv1.bn.running_mean', 'model.model.6.m.1.cv1.bn.running_var', 'model.model.6.m.1.cv1.bn.num_batches_tracked', 'model.model.6.m.1.cv2.conv.weight', 'model.model.6.m.1.cv2.bn.weight', 'model.model.6.m.1.cv2.bn.bias', 'model.model.6.m.1.cv2.bn.running_mean', 'model.model.6.m.1.cv2.bn.running_var', 'model.model.6.m.1.cv2.bn.num_batches_tracked', 'model.model.6.m.2.cv1.conv.weight', 'model.model.6.m.2.cv1.bn.weight', 'model.model.6.m.2.cv1.bn.bias', 'model.model.6.m.2.cv1.bn.running_mean', 'model.model.6.m.2.cv1.bn.running_var', 'model.model.6.m.2.cv1.bn.num_batches_tracked', 'model.model.6.m.2.cv2.conv.weight', 'model.model.6.m.2.cv2.bn.weight', 'model.model.6.m.2.cv2.bn.bias', 'model.model.6.m.2.cv2.bn.running_mean', 'model.model.6.m.2.cv2.bn.running_var', 'model.model.6.m.2.cv2.bn.num_batches_tracked', 'model.model.6.m.3.cv1.conv.weight', 'model.model.6.m.3.cv1.bn.weight', 'model.model.6.m.3.cv1.bn.bias', 'model.model.6.m.3.cv1.bn.running_mean', 'model.model.6.m.3.cv1.bn.running_var', 'model.model.6.m.3.cv1.bn.num_batches_tracked', 'model.model.6.m.3.cv2.conv.weight', 'model.model.6.m.3.cv2.bn.weight', 'model.model.6.m.3.cv2.bn.bias', 'model.model.6.m.3.cv2.bn.running_mean', 'model.model.6.m.3.cv2.bn.running_var', 'model.model.6.m.3.cv2.bn.num_batches_tracked', 'model.model.6.m.4.cv1.conv.weight', 'model.model.6.m.4.cv1.bn.weight', 'model.model.6.m.4.cv1.bn.bias', 'model.model.6.m.4.cv1.bn.running_mean', 'model.model.6.m.4.cv1.bn.running_var', 'model.model.6.m.4.cv1.bn.num_batches_tracked', 'model.model.6.m.4.cv2.conv.weight', 'model.model.6.m.4.cv2.bn.weight', 'model.model.6.m.4.cv2.bn.bias', 'model.model.6.m.4.cv2.bn.running_mean', 'model.model.6.m.4.cv2.bn.running_var', 'model.model.6.m.4.cv2.bn.num_batches_tracked', 'model.model.6.m.5.cv1.conv.weight', 'model.model.6.m.5.cv1.bn.weight', 'model.model.6.m.5.cv1.bn.bias', 'model.model.6.m.5.cv1.bn.running_mean', 'model.model.6.m.5.cv1.bn.running_var', 'model.model.6.m.5.cv1.bn.num_batches_tracked', 'model.model.6.m.5.cv2.conv.weight', 'model.model.6.m.5.cv2.bn.weight', 'model.model.6.m.5.cv2.bn.bias', 'model.model.6.m.5.cv2.bn.running_mean', 'model.model.6.m.5.cv2.bn.running_var', 'model.model.6.m.5.cv2.bn.num_batches_tracked', 'model.model.7.conv.weight', 'model.model.7.bn.weight', 'model.model.7.bn.bias', 'model.model.7.bn.running_mean', 'model.model.7.bn.running_var', 'model.model.7.bn.num_batches_tracked', 'model.model.8.cv1.conv.weight', 'model.model.8.cv1.bn.weight', 'model.model.8.cv1.bn.bias', 'model.model.8.cv1.bn.running_mean', 'model.model.8.cv1.bn.running_var', 'model.model.8.cv1.bn.num_batches_tracked', 'model.model.8.cv2.conv.weight', 'model.model.8.cv2.bn.weight', 'model.model.8.cv2.bn.bias', 'model.model.8.cv2.bn.running_mean', 'model.model.8.cv2.bn.running_var', 'model.model.8.cv2.bn.num_batches_tracked', 'model.model.8.m.0.cv1.conv.weight', 'model.model.8.m.0.cv1.bn.weight', 'model.model.8.m.0.cv1.bn.bias', 'model.model.8.m.0.cv1.bn.running_mean', 'model.model.8.m.0.cv1.bn.running_var', 'model.model.8.m.0.cv1.bn.num_batches_tracked', 'model.model.8.m.0.cv2.conv.weight', 'model.model.8.m.0.cv2.bn.weight', 'model.model.8.m.0.cv2.bn.bias', 'model.model.8.m.0.cv2.bn.running_mean', 'model.model.8.m.0.cv2.bn.running_var', 'model.model.8.m.0.cv2.bn.num_batches_tracked', 'model.model.8.m.1.cv1.conv.weight', 'model.model.8.m.1.cv1.bn.weight', 'model.model.8.m.1.cv1.bn.bias', 'model.model.8.m.1.cv1.bn.running_mean', 'model.model.8.m.1.cv1.bn.running_var', 'model.model.8.m.1.cv1.bn.num_batches_tracked', 'model.model.8.m.1.cv2.conv.weight', 'model.model.8.m.1.cv2.bn.weight', 'model.model.8.m.1.cv2.bn.bias', 'model.model.8.m.1.cv2.bn.running_mean', 'model.model.8.m.1.cv2.bn.running_var', 'model.model.8.m.1.cv2.bn.num_batches_tracked', 'model.model.8.m.2.cv1.conv.weight', 'model.model.8.m.2.cv1.bn.weight', 'model.model.8.m.2.cv1.bn.bias', 'model.model.8.m.2.cv1.bn.running_mean', 'model.model.8.m.2.cv1.bn.running_var', 'model.model.8.m.2.cv1.bn.num_batches_tracked', 'model.model.8.m.2.cv2.conv.weight', 'model.model.8.m.2.cv2.bn.weight', 'model.model.8.m.2.cv2.bn.bias', 'model.model.8.m.2.cv2.bn.running_mean', 'model.model.8.m.2.cv2.bn.running_var', 'model.model.8.m.2.cv2.bn.num_batches_tracked', 'model.model.9.cv1.conv.weight', 'model.model.9.cv1.bn.weight', 'model.model.9.cv1.bn.bias', 'model.model.9.cv1.bn.running_mean', 'model.model.9.cv1.bn.running_var', 'model.model.9.cv1.bn.num_batches_tracked', 'model.model.9.cv2.conv.weight', 'model.model.9.cv2.bn.weight', 'model.model.9.cv2.bn.bias', 'model.model.9.cv2.bn.running_mean', 'model.model.9.cv2.bn.running_var', 'model.model.9.cv2.bn.num_batches_tracked', 'model.model.12.cv1.conv.weight', 'model.model.12.cv1.bn.weight', 'model.model.12.cv1.bn.bias', 'model.model.12.cv1.bn.running_mean', 'model.model.12.cv1.bn.running_var', 'model.model.12.cv1.bn.num_batches_tracked', 'model.model.12.cv2.conv.weight', 'model.model.12.cv2.bn.weight', 'model.model.12.cv2.bn.bias', 'model.model.12.cv2.bn.running_mean', 'model.model.12.cv2.bn.running_var', 'model.model.12.cv2.bn.num_batches_tracked', 'model.model.12.m.0.cv1.conv.weight', 'model.model.12.m.0.cv1.bn.weight', 'model.model.12.m.0.cv1.bn.bias', 'model.model.12.m.0.cv1.bn.running_mean', 'model.model.12.m.0.cv1.bn.running_var', 'model.model.12.m.0.cv1.bn.num_batches_tracked', 'model.model.12.m.0.cv2.conv.weight', 'model.model.12.m.0.cv2.bn.weight', 'model.model.12.m.0.cv2.bn.bias', 'model.model.12.m.0.cv2.bn.running_mean', 'model.model.12.m.0.cv2.bn.running_var', 'model.model.12.m.0.cv2.bn.num_batches_tracked', 'model.model.12.m.1.cv1.conv.weight', 'model.model.12.m.1.cv1.bn.weight', 'model.model.12.m.1.cv1.bn.bias', 'model.model.12.m.1.cv1.bn.running_mean', 'model.model.12.m.1.cv1.bn.running_var', 'model.model.12.m.1.cv1.bn.num_batches_tracked', 'model.model.12.m.1.cv2.conv.weight', 'model.model.12.m.1.cv2.bn.weight', 'model.model.12.m.1.cv2.bn.bias', 'model.model.12.m.1.cv2.bn.running_mean', 'model.model.12.m.1.cv2.bn.running_var', 'model.model.12.m.1.cv2.bn.num_batches_tracked', 'model.model.12.m.2.cv1.conv.weight', 'model.model.12.m.2.cv1.bn.weight', 'model.model.12.m.2.cv1.bn.bias', 'model.model.12.m.2.cv1.bn.running_mean', 'model.model.12.m.2.cv1.bn.running_var', 'model.model.12.m.2.cv1.bn.num_batches_tracked', 'model.model.12.m.2.cv2.conv.weight', 'model.model.12.m.2.cv2.bn.weight', 'model.model.12.m.2.cv2.bn.bias', 'model.model.12.m.2.cv2.bn.running_mean', 'model.model.12.m.2.cv2.bn.running_var', 'model.model.12.m.2.cv2.bn.num_batches_tracked', 'model.model.15.cv1.conv.weight', 'model.model.15.cv1.bn.weight', 'model.model.15.cv1.bn.bias', 'model.model.15.cv1.bn.running_mean', 'model.model.15.cv1.bn.running_var', 'model.model.15.cv1.bn.num_batches_tracked', 'model.model.15.cv2.conv.weight', 'model.model.15.cv2.bn.weight', 'model.model.15.cv2.bn.bias', 'model.model.15.cv2.bn.running_mean', 'model.model.15.cv2.bn.running_var', 'model.model.15.cv2.bn.num_batches_tracked', 'model.model.15.m.0.cv1.conv.weight', 'model.model.15.m.0.cv1.bn.weight', 'model.model.15.m.0.cv1.bn.bias', 'model.model.15.m.0.cv1.bn.running_mean', 'model.model.15.m.0.cv1.bn.running_var', 'model.model.15.m.0.cv1.bn.num_batches_tracked', 'model.model.15.m.0.cv2.conv.weight', 'model.model.15.m.0.cv2.bn.weight', 'model.model.15.m.0.cv2.bn.bias', 'model.model.15.m.0.cv2.bn.running_mean', 'model.model.15.m.0.cv2.bn.running_var', 'model.model.15.m.0.cv2.bn.num_batches_tracked', 'model.model.15.m.1.cv1.conv.weight', 'model.model.15.m.1.cv1.bn.weight', 'model.model.15.m.1.cv1.bn.bias', 'model.model.15.m.1.cv1.bn.running_mean', 'model.model.15.m.1.cv1.bn.running_var', 'model.model.15.m.1.cv1.bn.num_batches_tracked', 'model.model.15.m.1.cv2.conv.weight', 'model.model.15.m.1.cv2.bn.weight', 'model.model.15.m.1.cv2.bn.bias', 'model.model.15.m.1.cv2.bn.running_mean', 'model.model.15.m.1.cv2.bn.running_var', 'model.model.15.m.1.cv2.bn.num_batches_tracked', 'model.model.15.m.2.cv1.conv.weight', 'model.model.15.m.2.cv1.bn.weight', 'model.model.15.m.2.cv1.bn.bias', 'model.model.15.m.2.cv1.bn.running_mean', 'model.model.15.m.2.cv1.bn.running_var', 'model.model.15.m.2.cv1.bn.num_batches_tracked', 'model.model.15.m.2.cv2.conv.weight', 'model.model.15.m.2.cv2.bn.weight', 'model.model.15.m.2.cv2.bn.bias', 'model.model.15.m.2.cv2.bn.running_mean', 'model.model.15.m.2.cv2.bn.running_var', 'model.model.15.m.2.cv2.bn.num_batches_tracked', 'model.model.16.conv.weight', 'model.model.16.bn.weight', 'model.model.16.bn.bias', 'model.model.16.bn.running_mean', 'model.model.16.bn.running_var', 'model.model.16.bn.num_batches_tracked', 'model.model.18.cv1.conv.weight', 'model.model.18.cv1.bn.weight', 'model.model.18.cv1.bn.bias', 'model.model.18.cv1.bn.running_mean', 'model.model.18.cv1.bn.running_var', 'model.model.18.cv1.bn.num_batches_tracked', 'model.model.18.cv2.conv.weight', 'model.model.18.cv2.bn.weight', 'model.model.18.cv2.bn.bias', 'model.model.18.cv2.bn.running_mean', 'model.model.18.cv2.bn.running_var', 'model.model.18.cv2.bn.num_batches_tracked', 'model.model.18.m.0.cv1.conv.weight', 'model.model.18.m.0.cv1.bn.weight', 'model.model.18.m.0.cv1.bn.bias', 'model.model.18.m.0.cv1.bn.running_mean', 'model.model.18.m.0.cv1.bn.running_var', 'model.model.18.m.0.cv1.bn.num_batches_tracked', 'model.model.18.m.0.cv2.conv.weight', 'model.model.18.m.0.cv2.bn.weight', 'model.model.18.m.0.cv2.bn.bias', 'model.model.18.m.0.cv2.bn.running_mean', 'model.model.18.m.0.cv2.bn.running_var', 'model.model.18.m.0.cv2.bn.num_batches_tracked', 'model.model.18.m.1.cv1.conv.weight', 'model.model.18.m.1.cv1.bn.weight', 'model.model.18.m.1.cv1.bn.bias', 'model.model.18.m.1.cv1.bn.running_mean', 'model.model.18.m.1.cv1.bn.running_var', 'model.model.18.m.1.cv1.bn.num_batches_tracked', 'model.model.18.m.1.cv2.conv.weight', 'model.model.18.m.1.cv2.bn.weight', 'model.model.18.m.1.cv2.bn.bias', 'model.model.18.m.1.cv2.bn.running_mean', 'model.model.18.m.1.cv2.bn.running_var', 'model.model.18.m.1.cv2.bn.num_batches_tracked', 'model.model.18.m.2.cv1.conv.weight', 'model.model.18.m.2.cv1.bn.weight', 'model.model.18.m.2.cv1.bn.bias', 'model.model.18.m.2.cv1.bn.running_mean', 'model.model.18.m.2.cv1.bn.running_var', 'model.model.18.m.2.cv1.bn.num_batches_tracked', 'model.model.18.m.2.cv2.conv.weight', 'model.model.18.m.2.cv2.bn.weight', 'model.model.18.m.2.cv2.bn.bias', 'model.model.18.m.2.cv2.bn.running_mean', 'model.model.18.m.2.cv2.bn.running_var', 'model.model.18.m.2.cv2.bn.num_batches_tracked', 'model.model.19.conv.weight', 'model.model.19.bn.weight', 'model.model.19.bn.bias', 'model.model.19.bn.running_mean', 'model.model.19.bn.running_var', 'model.model.19.bn.num_batches_tracked', 'model.model.21.cv1.conv.weight', 'model.model.21.cv1.bn.weight', 'model.model.21.cv1.bn.bias', 'model.model.21.cv1.bn.running_mean', 'model.model.21.cv1.bn.running_var', 'model.model.21.cv1.bn.num_batches_tracked', 'model.model.21.cv2.conv.weight', 'model.model.21.cv2.bn.weight', 'model.model.21.cv2.bn.bias', 'model.model.21.cv2.bn.running_mean', 'model.model.21.cv2.bn.running_var', 'model.model.21.cv2.bn.num_batches_tracked', 'model.model.21.m.0.cv1.conv.weight', 'model.model.21.m.0.cv1.bn.weight', 'model.model.21.m.0.cv1.bn.bias', 'model.model.21.m.0.cv1.bn.running_mean', 'model.model.21.m.0.cv1.bn.running_var', 'model.model.21.m.0.cv1.bn.num_batches_tracked', 'model.model.21.m.0.cv2.conv.weight', 'model.model.21.m.0.cv2.bn.weight', 'model.model.21.m.0.cv2.bn.bias', 'model.model.21.m.0.cv2.bn.running_mean', 'model.model.21.m.0.cv2.bn.running_var', 'model.model.21.m.0.cv2.bn.num_batches_tracked', 'model.model.21.m.1.cv1.conv.weight', 'model.model.21.m.1.cv1.bn.weight', 'model.model.21.m.1.cv1.bn.bias', 'model.model.21.m.1.cv1.bn.running_mean', 'model.model.21.m.1.cv1.bn.running_var', 'model.model.21.m.1.cv1.bn.num_batches_tracked', 'model.model.21.m.1.cv2.conv.weight', 'model.model.21.m.1.cv2.bn.weight', 'model.model.21.m.1.cv2.bn.bias', 'model.model.21.m.1.cv2.bn.running_mean', 'model.model.21.m.1.cv2.bn.running_var', 'model.model.21.m.1.cv2.bn.num_batches_tracked', 'model.model.21.m.2.cv1.conv.weight', 'model.model.21.m.2.cv1.bn.weight', 'model.model.21.m.2.cv1.bn.bias', 'model.model.21.m.2.cv1.bn.running_mean', 'model.model.21.m.2.cv1.bn.running_var', 'model.model.21.m.2.cv1.bn.num_batches_tracked', 'model.model.21.m.2.cv2.conv.weight', 'model.model.21.m.2.cv2.bn.weight', 'model.model.21.m.2.cv2.bn.bias', 'model.model.21.m.2.cv2.bn.running_mean', 'model.model.21.m.2.cv2.bn.running_var', 'model.model.21.m.2.cv2.bn.num_batches_tracked', 'model.model.22.cv2.0.0.conv.weight', 'model.model.22.cv2.0.0.bn.weight', 'model.model.22.cv2.0.0.bn.bias', 'model.model.22.cv2.0.0.bn.running_mean', 'model.model.22.cv2.0.0.bn.running_var', 'model.model.22.cv2.0.0.bn.num_batches_tracked', 'model.model.22.cv2.0.1.conv.weight', 'model.model.22.cv2.0.1.bn.weight', 'model.model.22.cv2.0.1.bn.bias', 'model.model.22.cv2.0.1.bn.running_mean', 'model.model.22.cv2.0.1.bn.running_var', 'model.model.22.cv2.0.1.bn.num_batches_tracked', 'model.model.22.cv2.0.2.weight', 'model.model.22.cv2.0.2.bias', 'model.model.22.cv2.1.0.conv.weight', 'model.model.22.cv2.1.0.bn.weight', 'model.model.22.cv2.1.0.bn.bias', 'model.model.22.cv2.1.0.bn.running_mean', 'model.model.22.cv2.1.0.bn.running_var', 'model.model.22.cv2.1.0.bn.num_batches_tracked', 'model.model.22.cv2.1.1.conv.weight', 'model.model.22.cv2.1.1.bn.weight', 'model.model.22.cv2.1.1.bn.bias', 'model.model.22.cv2.1.1.bn.running_mean', 'model.model.22.cv2.1.1.bn.running_var', 'model.model.22.cv2.1.1.bn.num_batches_tracked', 'model.model.22.cv2.1.2.weight', 'model.model.22.cv2.1.2.bias', 'model.model.22.cv2.2.0.conv.weight', 'model.model.22.cv2.2.0.bn.weight', 'model.model.22.cv2.2.0.bn.bias', 'model.model.22.cv2.2.0.bn.running_mean', 'model.model.22.cv2.2.0.bn.running_var', 'model.model.22.cv2.2.0.bn.num_batches_tracked', 'model.model.22.cv2.2.1.conv.weight', 'model.model.22.cv2.2.1.bn.weight', 'model.model.22.cv2.2.1.bn.bias', 'model.model.22.cv2.2.1.bn.running_mean', 'model.model.22.cv2.2.1.bn.running_var', 'model.model.22.cv2.2.1.bn.num_batches_tracked', 'model.model.22.cv2.2.2.weight', 'model.model.22.cv2.2.2.bias', 'model.model.22.cv3.0.0.conv.weight', 'model.model.22.cv3.0.0.bn.weight', 'model.model.22.cv3.0.0.bn.bias', 'model.model.22.cv3.0.0.bn.running_mean', 'model.model.22.cv3.0.0.bn.running_var', 'model.model.22.cv3.0.0.bn.num_batches_tracked', 'model.model.22.cv3.0.1.conv.weight', 'model.model.22.cv3.0.1.bn.weight', 'model.model.22.cv3.0.1.bn.bias', 'model.model.22.cv3.0.1.bn.running_mean', 'model.model.22.cv3.0.1.bn.running_var', 'model.model.22.cv3.0.1.bn.num_batches_tracked', 'model.model.22.cv3.0.2.weight', 'model.model.22.cv3.0.2.bias', 'model.model.22.cv3.1.0.conv.weight', 'model.model.22.cv3.1.0.bn.weight', 'model.model.22.cv3.1.0.bn.bias', 'model.model.22.cv3.1.0.bn.running_mean', 'model.model.22.cv3.1.0.bn.running_var', 'model.model.22.cv3.1.0.bn.num_batches_tracked', 'model.model.22.cv3.1.1.conv.weight', 'model.model.22.cv3.1.1.bn.weight', 'model.model.22.cv3.1.1.bn.bias', 'model.model.22.cv3.1.1.bn.running_mean', 'model.model.22.cv3.1.1.bn.running_var', 'model.model.22.cv3.1.1.bn.num_batches_tracked', 'model.model.22.cv3.1.2.weight', 'model.model.22.cv3.1.2.bias', 'model.model.22.cv3.2.0.conv.weight', 'model.model.22.cv3.2.0.bn.weight', 'model.model.22.cv3.2.0.bn.bias', 'model.model.22.cv3.2.0.bn.running_mean', 'model.model.22.cv3.2.0.bn.running_var', 'model.model.22.cv3.2.0.bn.num_batches_tracked', 'model.model.22.cv3.2.1.conv.weight', 'model.model.22.cv3.2.1.bn.weight', 'model.model.22.cv3.2.1.bn.bias', 'model.model.22.cv3.2.1.bn.running_mean', 'model.model.22.cv3.2.1.bn.running_var', 'model.model.22.cv3.2.1.bn.num_batches_tracked', 'model.model.22.cv3.2.2.weight', 'model.model.22.cv3.2.2.bias', 'model.model.22.dfl.conv.weight'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "\n",
    "# Initialize pretrained model\n",
    "#model = YOLO('yolov8n.pt')\n",
    "\n",
    "model = YOLO(\"/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt\")\n",
    "\n",
    "# Keep a copy of old state dict for sanity check\n",
    "old_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# We should freeze all but the last layer\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to put the frozen layers in eval mode to prevent BN values\n",
    "# from changing.\n",
    "def put_in_eval_mode(trainer, n_layers=22):\n",
    "  for i, (name, module) in enumerate(trainer.model.named_modules()):\n",
    "    if name.endswith(\"bn\") and int(name.split('.')[1]) < n_layers:\n",
    "      module.eval()\n",
    "      module.track_running_stats = False\n",
    "      # print(name, \" put in eval mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_callback(\"on_train_epoch_start\", put_in_eval_mode)\n",
    "model.add_callback(\"on_pretrain_routine_start\", put_in_eval_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available 😃 Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/nn/tasks.py:785: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.55 🚀 Python-3.10.12 torch-2.4.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7721MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt, data=/home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/data.yaml, epochs=500, time=None, patience=100, batch=6, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train82, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=22, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train82\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train82', view at http://localhost:6006/\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5595907  ultralytics.nn.modules.head.Detect           [17, [256, 512, 512]]         \n",
      "YOLOv8l summary: 365 layers, 43,642,947 parameters, 43,642,931 gradients\n",
      "\n",
      "Transferred 595/595 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.5.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.5.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.5.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.5.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.5.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.5.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.4.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.4.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.4.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.4.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.4.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.4.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.5.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.5.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.5.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.5.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.5.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.5.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.12.cv1.conv.weight'\n",
      "Freezing layer 'model.12.cv1.bn.weight'\n",
      "Freezing layer 'model.12.cv1.bn.bias'\n",
      "Freezing layer 'model.12.cv2.conv.weight'\n",
      "Freezing layer 'model.12.cv2.bn.weight'\n",
      "Freezing layer 'model.12.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.15.cv1.conv.weight'\n",
      "Freezing layer 'model.15.cv1.bn.weight'\n",
      "Freezing layer 'model.15.cv1.bn.bias'\n",
      "Freezing layer 'model.15.cv2.conv.weight'\n",
      "Freezing layer 'model.15.cv2.bn.weight'\n",
      "Freezing layer 'model.15.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.16.conv.weight'\n",
      "Freezing layer 'model.16.bn.weight'\n",
      "Freezing layer 'model.16.bn.bias'\n",
      "Freezing layer 'model.18.cv1.conv.weight'\n",
      "Freezing layer 'model.18.cv1.bn.weight'\n",
      "Freezing layer 'model.18.cv1.bn.bias'\n",
      "Freezing layer 'model.18.cv2.conv.weight'\n",
      "Freezing layer 'model.18.cv2.bn.weight'\n",
      "Freezing layer 'model.18.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.19.conv.weight'\n",
      "Freezing layer 'model.19.bn.weight'\n",
      "Freezing layer 'model.19.bn.bias'\n",
      "Freezing layer 'model.21.cv1.conv.weight'\n",
      "Freezing layer 'model.21.cv1.bn.weight'\n",
      "Freezing layer 'model.21.cv1.bn.bias'\n",
      "Freezing layer 'model.21.cv2.conv.weight'\n",
      "Freezing layer 'model.21.cv2.bn.weight'\n",
      "Freezing layer 'model.21.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/utils/checks.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:267: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/labels.cache... 25063 images, 1032 backgrounds, 0 corrupt: 100%|██████████| 25063/25063 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/63cdb929ca7224dec6760700_1082.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_0_63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_0_63cdb929ca7224dec6760700_1082.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_1_63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/val/labels.cache... 2435 images, 186 backgrounds, 0 corrupt: 100%|██████████| 2436/2436 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train82/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.000515625), 103 bias(decay=0.0)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/model.py:650\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:323\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[1;32m    326\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[0;32m~/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:315\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_scheduler()\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpatience), \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# do not move\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_pretrain_routine_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:690\u001b[0m, in \u001b[0;36mBaseTrainer.resume_training\u001b[0;34m(self, ckpt)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mstate_dict())  \u001b[38;5;66;03m# EMA\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mupdates \u001b[38;5;241m=\u001b[39m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m start_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, (\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs is finished, nothing to resume.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart a new training without resuming, i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo train model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResuming training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m<\u001b[39m start_epoch:\n",
      "\u001b[0;31mAssertionError\u001b[0m: /home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/last.pt'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = model.train(resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.74 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.55 🚀 Python-3.10.12 torch-2.4.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7940MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train7/weights/last.pt, data=/home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/data.yaml, epochs=500, time=None, patience=100, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=22, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5595907  ultralytics.nn.modules.head.Detect           [17, [256, 512, 512]]         \n",
      "YOLOv8l summary: 365 layers, 43,642,947 parameters, 43,642,931 gradients\n",
      "\n",
      "Transferred 595/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.5.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.5.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.5.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.5.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.5.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.5.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.4.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.4.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.4.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.4.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.4.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.4.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.5.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.5.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.5.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.5.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.5.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.5.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.12.cv1.conv.weight'\n",
      "Freezing layer 'model.12.cv1.bn.weight'\n",
      "Freezing layer 'model.12.cv1.bn.bias'\n",
      "Freezing layer 'model.12.cv2.conv.weight'\n",
      "Freezing layer 'model.12.cv2.bn.weight'\n",
      "Freezing layer 'model.12.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.15.cv1.conv.weight'\n",
      "Freezing layer 'model.15.cv1.bn.weight'\n",
      "Freezing layer 'model.15.cv1.bn.bias'\n",
      "Freezing layer 'model.15.cv2.conv.weight'\n",
      "Freezing layer 'model.15.cv2.bn.weight'\n",
      "Freezing layer 'model.15.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.16.conv.weight'\n",
      "Freezing layer 'model.16.bn.weight'\n",
      "Freezing layer 'model.16.bn.bias'\n",
      "Freezing layer 'model.18.cv1.conv.weight'\n",
      "Freezing layer 'model.18.cv1.bn.weight'\n",
      "Freezing layer 'model.18.cv1.bn.bias'\n",
      "Freezing layer 'model.18.cv2.conv.weight'\n",
      "Freezing layer 'model.18.cv2.bn.weight'\n",
      "Freezing layer 'model.18.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.19.conv.weight'\n",
      "Freezing layer 'model.19.bn.weight'\n",
      "Freezing layer 'model.19.bn.bias'\n",
      "Freezing layer 'model.21.cv1.conv.weight'\n",
      "Freezing layer 'model.21.cv1.bn.weight'\n",
      "Freezing layer 'model.21.cv1.bn.bias'\n",
      "Freezing layer 'model.21.cv2.conv.weight'\n",
      "Freezing layer 'model.21.cv2.bn.weight'\n",
      "Freezing layer 'model.21.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.2.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.2.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.2.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.2.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.2.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.2.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/nn/tasks.py:785: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/utils/checks.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU) 7.75G total, 0.38G reserved, 0.37G allocated, 7.00G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/engine/trainer.py:267: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/ultralytics/utils/autobatch.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    43642947           0         1.070         33.17         63.61        (1, 3, 640, 640)                    list\n",
      "    43642947           0         1.638         38.68         40.78        (2, 3, 640, 640)                    list\n",
      "    43642947           0         2.791         58.54         75.56        (4, 3, 640, 640)                    list\n",
      "    43642947           0         5.037         128.3           154        (8, 3, 640, 640)                    list\n",
      "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 7.74 GiB memory in use. Of the allocated memory 7.41 GiB is allocated by PyTorch, and 178.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 6 for CUDA:0 4.67G/7.75G (60%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/labels.cache... 25063 images, 1032 backgrounds, 0 corrupt: 100%|██████████| 25063/25063 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/63cdb929ca7224dec6760700_1082.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_0_63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_0_63cdb929ca7224dec6760700_1082.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/train/images/aug_1_63cc870fca7224dec6e36386_710.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/val/labels.cache... 2435 images, 186 backgrounds, 0 corrupt: 100%|██████████| 2436/2436 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.000515625), 103 bias(decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Train the model. Freeze the first 22 layers [0-21].\n",
    "results = model.train(data='/home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/data.yaml', freeze=22, epochs=500, imgsz=640, batch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/home/areebadnan/Areeb_code/work/Atheritia/ultralytics/runs/detect/train8/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.55 🚀 Python-3.10.12 torch-2.4.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7940MiB)\n",
      "YOLOv8l summary (fused): 268 layers, 43,619,715 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/val/labels.cache... 2435 images, 186 backgrounds, 0 corrupt: 100%|██████████| 2436/2436 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 153/153 [00:51<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2436       6352       0.54      0.313      0.344      0.172\n",
      "                  Audi        491       1040      0.932      0.398      0.563      0.279\n",
      "              Mercedes         76         80      0.309      0.275       0.21     0.0861\n",
      "                Toyota         60         60      0.185      0.133     0.0866     0.0369\n",
      "               Porsche         32         35      0.146      0.171     0.0803     0.0328\n",
      "                  Nike         94        137      0.567      0.124      0.136     0.0471\n",
      "                Adidas        681       1138        0.8      0.402      0.482      0.273\n",
      "          Fly-Emirates         86        122      0.544      0.607      0.619      0.397\n",
      "                Hummel        360        416      0.703      0.123      0.162     0.0821\n",
      "             Coca-Cola         12         23      0.087      0.391      0.258      0.178\n",
      "                 Qatar        222        222      0.798      0.505       0.65      0.251\n",
      "              T-Mobile        852       1878      0.648      0.463      0.524      0.215\n",
      "               Allianz         87        102      0.567       0.49      0.528      0.315\n",
      "                  bwin        126        225      0.542     0.0578      0.191     0.0877\n",
      "                  DEVK         42         43      0.242      0.302      0.247      0.115\n",
      "          RheinEnergie        128        172      0.794      0.314      0.346       0.16\n",
      "                  Rewe        492        659      0.771       0.25      0.419      0.196\n",
      "Speed: 0.2ms preprocess, 18.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val23\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"/home/areebadnan/Areeb_code/work/Atheritia/Datasets/17_logo_dataset_for_head_training/data.yaml\", conf = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
